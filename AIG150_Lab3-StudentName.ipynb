{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3\n",
    "Exploratory Data Analysis\n",
    "\n",
    "### Learning objectives \n",
    "Upon successful completion of this lab, you will have demonstrated the abilities to: \n",
    "1. Describing numeric and categorical distributions\n",
    "2. Estimating correlation and association\n",
    "3. Working with different data types and doing type conversions\n",
    "4. Working with Strings and String Processing\n",
    "5. Testing mean differences in groups\n",
    "6. Visualizing distributions, relationships, and groups\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "customer = pd.read_csv('customer_demographics.csv')\n",
    "customer.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Print the first five records from the customer dataframe to get an idea about the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Change customer_id type to category. Then print the types of all columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a DataFrame with missing values\n",
    "df = pd.DataFrame({'A': [1, np.nan, 3, np.nan, 5],\n",
    "                   'B': [np.nan, 2, np.nan, 4, np.nan]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Convert all the column names to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scipy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m chi2_contingency\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Create a DataFrame\u001b[39;00m\n\u001b[1;32m      5\u001b[0m data \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCategory\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOutcome\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYes\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYes\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYes\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      8\u001b[0m }\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'scipy'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Create a DataFrame\n",
    "data = {\n",
    "    'Category': ['A', 'A', 'B', 'B', 'A', 'A'],\n",
    "    'Outcome': ['Yes', 'No', 'Yes', 'No', 'Yes', 'No']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Create a contingency table (cross-tabulation)\n",
    "contingency_table = pd.crosstab(df['Category'], df['Outcome'])\n",
    "\n",
    "# Display the contingency table\n",
    "print(\"Contingency Table:\")\n",
    "print(contingency_table)\n",
    "\n",
    "# Perform the chi-square test\n",
    "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nChi-Square Statistic:\", chi2)\n",
    "print(\"P-value:\", p)\n",
    "print(\"Degrees of Freedom:\", dof)\n",
    "print(\"Expected Frequencies:\")\n",
    "print(pd.DataFrame(expected, index=contingency_table.index, columns=contingency_table.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B\n",
      "0  1.0  2.0\n",
      "1  3.0  2.0\n",
      "2  3.0  4.0\n",
      "3  5.0  4.0\n",
      "4  5.0  NaN\n"
     ]
    }
   ],
   "source": [
    "# Forward fill missing values\n",
    "forward_filled_df = df.bfill()\n",
    "print(forward_filled_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.Check if the first customer id matches the pattern. \n",
    "- Define a pattern that checks for exactly 6 digits in a string\n",
    "- Compile the 6-digits pattern in a variable p. \n",
    "- Call the p.match() by passing the first customer id as argument. Use customer.iloc[0,1] which is the customer in the first row of the the dataframe. \n",
    "- print the return value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.Check if all customer id values match the pattern. \n",
    "- Compile the 6-digits pattern in a variable p. \n",
    "- Use map() function and pass p.match as predicate function/first argument and the customer_id column as second argument. \n",
    "- Wrap the return value in a list named customer_id_m. \n",
    "- write a for loop, that will iterate through the matches list (customer_id_m), and print a message if there is no match. \n",
    "\n",
    "Expected output: \n",
    "\n",
    "customer id 1001036 in row 1 : does not match the pattern\n",
    "customer id 10b1036 in row 2 : does not match the pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.Check and treat errors in the education column.\n",
    "- Display the list of unique values for  education\n",
    "- lowercase all values under the education column. use mydf[colname].str.lower(). Keep the original column 'education' and add a new column named 'education_lowercase'. \n",
    "- after lowercasing, display the list of unique values for  education_lowercase column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.Copy values between columns and Drop columns \n",
    "- Assign the education_lower values to education. \n",
    "- drop the education_lowercase column \n",
    "- show the top rows of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.Find and correct errors in the job column.  \n",
    "- show the list of unique values under the job column. Use value_counts() method. \n",
    "- admin. and ADMINISTRATION should refer to the same category level. replace all ADMINISTRATION occurrences with 'admin.' Use the replace() method. syntax: mydataframe.columnname.replace(oldvalue, newvalue) \n",
    "- after you make the changes, show again the list of unique values under the job column. \n",
    "\n",
    "ref: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.replace.html?highlight=replace#pandas.DataFrame.replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Add a new column to the dataframe by taking the first 3 letters of the marital column. \n",
    "- Note: you should lowercase all values for the marital column. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11.Add a dummy variable\n",
    "- Add a new column marital_b to the dataframe that takes the value 0 if marital is single, 1 if marital is married and 2 if marital is divorced. \n",
    "- Hint: use the replace method on the required column and pass a dictionary of oldValue:newValue items for replacement.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12.Customized binning \n",
    "- add a new column age_group based on age. If age is <35, age_group is set to young. if age between 36 and 55, the age_group is set to 'middle'. if age is >55, age_group is set to 'senior'.\n",
    "\n",
    "    Use conditional assignment: https://datatofish.com/if-condition-in-pandas-dataframe/\n",
    "\n",
    "This is the general structure that you may use to create the IF condition:\n",
    "\n",
    "    df.loc[df['column name'] condition, 'new column name'] = 'value if condition is met'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13.Download the Boston Housing dataset from https://www.kaggle.com/datasets/arunjangir245/boston-housing-dataset\n",
    "Read the csv file into a dataframe called boston.\n",
    "Print the first 5 records from the boston dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fatal Python error: pyinit_core_reconfigure: failed to read thread state\n",
      "Python runtime state: initialized\n",
      "\n",
      "Thread 0x000000016ee13000 (most recent call first):\n",
      "  File \"/private/var/containers/Bundle/Application/318DE3E9-2B46-4A75-89ED-27CF35AB5FFE/Carnets.app/Library/lib/python3.11/concurrent/futures/thread.py\", line 81 in _worker\n",
      "  File \"/private/var/containers/Bundle/Application/318DE3E9-2B46-4A75-89ED-27CF35AB5FFE/Carnets.app/Library/lib/python3.11/threading.py\", line 975 in run\n",
      "  File \"/private/var/containers/Bundle/Application/318DE3E9-2B46-4A75-89ED-27CF35AB5FFE/Carnets.app/Library/lib/python3.11/threading.py\", line 1038 in _bootstrap_inner\n",
      "  File \"/private/var/containers/Bundle/Application/318DE3E9-2B46-4A75-89ED-27CF35AB5FFE/Carnets.app/Library/lib/python3.11/threading.py\", line 995 in _bootstrap\n",
      "\n",
      "Thread 0x000000016dd7b000 (most recent call first):\n",
      "  File \"/private/var/containers/Bundle/Application/318DE3E9-2B46-4A75-89ED-27CF35AB5FFE/Carnets.app/Library/lib/python3.11/selectors.py\", line 561 in select\n",
      "  File \"/private/var/containers/Bundle/Application/318DE3E9-2B46-4A75-89ED-27CF35AB5FFE/Carnets.app/Library/lib/python3.11/asyncio/base_events.py\", line 1876 in _run_once\n",
      "  File \"/private/var/containers/Bundle/Application/318DE3E9-2B46-4A75-89ED-27CF35AB5FFE/Carnets.app/Library/lib/python3.11/asyncio/base_events.py\", line 607 in run_forever\n",
      "  File \"/private/var/containers/Bundle/Application/318DE3E9-2B46-4A75-89ED-27CF35AB5FFE/Carnets.app/Library/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 195 in start\n",
      "  File \"/private/var/containers/Bundle/Application/318DE3E9-2B46-4A75-89ED-27CF35AB5FFE/Carnets.app/Library/lib/python3.11/site-packages/jupyter_server/serverapp.py\", line 2939 in start_ioloop\n",
      "  File \"/private/var/containers/Bundle/Application/318DE3E9-2B46-4A75-89ED-27CF35AB5FFE/Carnets.app/Library/lib/python3.11/site-packages/jupyter_server/serverapp.py\", line 2953 in start\n",
      "  File \"/private/var/containers/Bundle/Application/318DE3E9-2B46-4A75-89ED-27CF35AB5FFE/Carnets.app/Library/lib/python3.11/site-packages/jupyter_server/extension/application.py\", line 617 in launch_instance\n",
      "  File \"/private/var/containers/Bundle/Application/318DE3E9-2B46-4A75-89ED-27CF35AB5FFE/Carnets.app/Library/bin/jupyter-notebook\", line 8 in <module>\n",
      "\r"
     ]
    }
   ],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14.Show the quantile table for the numerical columns of boston dataset using the quantile() function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_boston\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Load the Boston dataset\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Boston dataset\n",
    "boston = load_boston()\n",
    "boston_df = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "\n",
    "# Calculate quantiles for numerical columns\n",
    "quantile_table = boston_df.quantile([0.25, 0.5, 0.75])\n",
    "\n",
    "# Display the quantile table\n",
    "print(quantile_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15.Show the summary statistics of boston dataset using the describe() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16.First run the following command\n",
    "print(boston.shape) and copy the result\n",
    "\n",
    "We will now do the equal-sized binning:\n",
    "\n",
    "        create a new dataframe boston_binned, result of equal-sized binning of all the numerical columns in boston dataset given the percentile points in the quantile table. \n",
    "        Use a for loop to iterate over the columns in boston dataset, and call qcut for binning each of the columns. \n",
    "\n",
    "        Refer to: ch13: exploring data analysis, page 4(Python for Data Science for Dummies, 2nd Edition), section: counting for categorical Data.\n",
    "\n",
    "        print the first 5 rows of boston_binned dataset using the head() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17.Show the frequency table for the variable CRIM in boston_binned. Use value_counts() function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18.Study the relationship between CRIM and MEDV categorical variables in boston_binned dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "19.calculate the chi-square and the associated p-value betweeb CRIM and MEDV in boston_binned dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "20.Below are the intervals for the variable MEDV in boston_binned dataframe. \n",
    "    1. define a dictionary palette of interval names as keys and colors of your choice as values. \n",
    "    2. print the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_binned['MEDV'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "21.Plotting scatterplots: \n",
    "    1. display a scatter chart with the MEDV on the y axis and DIS on the x axis. Highlight the different intervals of MEDV with different colors. \n",
    "    3. interpret the scatter plot.  \n",
    "    reuse code in ch13, page 7, section: Plotting Scatterplots from Python for Data Science for Dummies, 2nd Edition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "22.plotting scatterplots: \n",
    "    1. display a scatter chart with the MEDV on the y axis and DIS on the x axis. Highlight the different intervals of MEDV with different colors. \n",
    "    3. interpret the scatter plot.  \n",
    "    reuse code in ch13, page 7, section: Plotting Scatterplots from Python for Data Science for Dummies, 2nd Edition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "23.display a scatter matrix with only the following variables: \n",
    "CRIM, ZN, INDUS, RM and MEDV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
